'''
ideas:
æš‚æ— 
'''

import pandas as pd
import numpy as np
import streamlit as st

# MLç›¸å…³åº“
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.preprocessing import PolynomialFeatures,StandardScaler
from sklearn.model_selection import KFold,GridSearchCV,train_test_split,RandomizedSearchCV
from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error

# DLç›¸å…³åº“
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import AdamW
from model import TimeSeriesTransformer
from transformers import TimeSeriesTransformerConfig,TimeSeriesTransformerForPrediction,InformerConfig,InformerForPrediction
from transformers import PretrainedConfig

# æ—¶é—´åºåˆ—ç›¸å…³åº“
from gluonts.dataset.common import ListDataset
from gluonts.dataset.field_names import FieldName
from gluonts.time_feature import time_features_from_frequency_str,get_lags_for_frequency,TimeFeature
from gluonts.transform import (
    AddAgeFeature,AddTimeFeatures,VstackFeatures,
    AddObservedValuesIndicator,
    Chain,
    RenameFields,RemoveFields,SelectFields,
    InstanceSplitter,
)
from gluonts.transform.sampler import ExpectedNumInstanceSampler,ValidationSplitSampler,TestSplitSampler
from gluonts.itertools import Cyclic, IterableSlice, PseudoShuffled
from gluonts.torch.util import IterableDataset

# ä½œå›¾
from pylab import mpl,plt

# è‡ªå®šä¹‰ç±»
from predict import ML_predict,DL_predict,TST_predict,Informer_predict
from utils import printMetric,selectHyperparameters

col1,col2=st.columns(2)
# é€‰æ‹©æ¨¡å‹
with col1:
    with st.form('users choose models'):
        add_select_model=st.multiselect(
            'è¯·é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªé¢„æµ‹æ¨¡å‹',
            ['çº¿æ€§å›å½’','æ”¯æŒå‘é‡æœº','Transformer','ğŸ¤— Time Series Transformer','ğŸ¤— Informer']
        )
        submitted1 = st.form_submit_button('ç¡®è®¤')
# é€‰æ‹©æ•°æ®èŒƒå›´
with col2:
    with st.form('users choose data ranges'):
        add_select_region=st.multiselect(
            'è¯·é€‰æ‹©ä¸€ä¸ªé¢„æµ‹çš„åŒºåŸŸ',
            st.session_state['data'].columns
        )
        add_select_time=st.slider(
            'è¯·é€‰æ‹©æ•°æ®çš„èµ·æ­¢æ—¥æœŸ',
            value=(st.session_state['data'].index[0].to_pydatetime(),st.session_state['data'].index[-1].to_pydatetime()),
            format='YYYY/MM/DD',
        )
        submitted2 = st.form_submit_button('ç¡®è®¤')

if submitted1 or submitted2:
    # å°†æ‰€é€‰æ•°æ®æ ‡å‡†åŒ–
    data=st.session_state['data'].loc[add_select_time[0]:add_select_time[1]]
    scaler=StandardScaler()
    data_pred=scaler.fit_transform(data)
    data_pred=pd.DataFrame(data_pred,index=data.index,columns=data.columns)

    # å‘ç”¨æˆ·å±•ç¤ºæ•°æ®
    col1,col2,col3=st.columns(3)
    with col1:
        st.write('æ‚¨æ‰€é€‰æ‹©çš„æ¨¡å‹æ˜¯ï¼š')
        for idx in range(len(add_select_model)):
            st.write(add_select_model[idx])
    with col2:
        st.write('æ‚¨æ‰€é€‰æ‹©çš„åŒºåŸŸæ˜¯ï¼š')
        for idx in range(len(add_select_region)):
            st.write(add_select_region[idx])
    with col3:
        st.write('æ‚¨æ‰€é€‰æ‹©çš„èµ·æ­¢æ—¥æœŸæ˜¯ï¼š')
        for idx in range(len(add_select_time)):
            st.write(add_select_time[idx])
    st.line_chart(data_pred[add_select_region])


# é€‰æ‹©è¶…å‚æ•°
with st.sidebar:
    st.header('æ¨¡å‹çš„è¶…å‚æ•°é€‰æ‹©')
    for model_name in add_select_model:
        if model_name=='çº¿æ€§å›å½’':
            st.subheader(model_name)
            lr_kwargs=selectHyperparameters(
                model_name,
                [{'name':'fit_intercept','type':str,'help':'æ‹Ÿåˆæˆªè·','range':[True,False]},]
            )
            st.write(f'{model_name}çš„è¶…å‚æ•°ï¼š')
            st.write(lr_kwargs)

        if model_name=='æ”¯æŒå‘é‡æœº':
            st.subheader(model_name)
            svr_kwargs=selectHyperparameters(
                model_name,
                [{'name':'kernel','type':str,'help':'SVMçš„æ ¸å‡½æ•°','range':['poly','linear', 'rbf', 'sigmoid', 'precomputed']},
                 {'name':'degree','type':int,'help':'äºŒé¡¹æ ¸çš„ç³»æ•°','range':[1,5]},
                 {'name':'tol','type':float,'help':'Tolerance for stopping criterion','range':[1e-4,1e-2]},
                 {'name':'C','type':float,'help':'æ­£åˆ™åŒ–ç³»æ•°','range':[0.1,5.0]},]
            )
            st.write(f'{model_name}çš„è¶…å‚æ•°ï¼š')
            st.write(svr_kwargs)
        
        if model_name=='ğŸ¤— Time Series Transformer':
            st.subheader(model_name)
            tst_kwargs=selectHyperparameters(
                model_name,
                [{'name':'prediction_length','type':int,'help':'ä¼ å…¥encoderçš„åºåˆ—é•¿åº¦','range':[10,100]},
                 {'name':'context_length','type':int,'help':'ä¼ å…¥decoderçš„åºåˆ—é•¿åº¦','range':[5,50]},
                 {'name':'n_encoder_layers','type':int,'help':'encoderçš„å±‚æ•°','range':[1,10]},
                 {'name':'n_decoder_layers','type':int,'help':'decoderçš„å±‚æ•°','range':[1,10]},
                 {'name':'d_model','type':int,'help':'æ—¥åè¡¥å……','range':[4,32]},
                 {'name':'train_dataloader_batch_size','type':int,'help':'è®­ç»ƒé›†çš„batch size','range':[16,256]},
                 {'name':'test_dataloader_batch_size','type':int,'help':'æµ‹è¯•é›†çš„batch size','range':[8,128]},
                 {'name':'epochs','type':int,'help':'è®­ç»ƒè½®æ•°','range':[1,100]},
                 {'name':'logging_steps','type':int,'help':'æ¯è®­ç»ƒæŒ‡å®šä¸ªæ•°çš„batchï¼Œæ‰“å°loss','range':[10,100]},]
            )
            st.write(f'{model_name}çš„è¶…å‚æ•°ï¼š')
            st.write(tst_kwargs)

        if model_name=='ğŸ¤— Informer':
            st.subheader(model_name)
            ifm_kwargs=selectHyperparameters(
                model_name,
                [{'name':'prediction_length','type':int,'help':'ä¼ å…¥encoderçš„åºåˆ—é•¿åº¦','range':[10,100]},
                 {'name':'context_length','type':int,'help':'ä¼ å…¥decoderçš„åºåˆ—é•¿åº¦','range':[5,50]},
                 {'name':'n_encoder_layers','type':int,'help':'encoderçš„å±‚æ•°','range':[1,10]},
                 {'name':'n_decoder_layers','type':int,'help':'decoderçš„å±‚æ•°','range':[1,10]},
                 {'name':'d_model','type':int,'help':'æ—¥åè¡¥å……','range':[4,32]},
                 {'name':'train_dataloader_batch_size','type':int,'help':'è®­ç»ƒé›†çš„batch size','range':[16,256]},
                 {'name':'test_dataloader_batch_size','type':int,'help':'æµ‹è¯•é›†çš„batch size','range':[8,128]},
                 {'name':'epochs','type':int,'help':'è®­ç»ƒè½®æ•°','range':[1,100]},
                 {'name':'logging_steps','type':int,'help':'æ¯è®­ç»ƒæŒ‡å®šä¸ªæ•°çš„batchï¼Œæ‰“å°loss','range':[10,100]},]
            )
            st.write(f'{model_name}çš„è¶…å‚æ•°ï¼š')
            st.write(ifm_kwargs)

# æ ¹æ®ç”¨æˆ·æ‰€é€‰æ•°æ®ä¸æ¨¡å‹è¿›è¡Œé¢„æµ‹å¹¶å¯è§†åŒ–
if submitted1 or submitted2:
    st.caption('æ•°æ®å·²æ ‡å‡†åŒ–')
    for model_name in add_select_model:
        if model_name=='çº¿æ€§å›å½’':
            model=LinearRegression(**lr_kwargs)
            lr=ML_predict(data_pred[add_select_region],5,1)
            metric=lr(model,0.3)#lr()è¿”å›æŒ‡æ ‡ç»„æˆçš„å­—å…¸
            printMetric(model_name,metric)

        if model_name=='æ”¯æŒå‘é‡æœº':
            model=SVR(**svr_kwargs)
            svr=ML_predict(data_pred[add_select_region],5,1)
            metric=svr(model,0.3)#lr()è¿”å›æŒ‡æ ‡ç»„æˆçš„å­—å…¸
            printMetric(model_name,metric)

        if model_name=='Transformer':
            model=TimeSeriesTransformer(nvars=1,d_model=512,d_hid=128,nheads=8,nlayers=2,dropout=0.1)
            tst=DL_predict(data_pred[add_select_region],5,1)
            metric=tst(model,0.3,4)
            printMetric(model_name,metric)

        if model_name=='ğŸ¤— Time Series Transformer':

            # hyperparameters
            lags_seq=[1,2,3]
            freq='1D'
            num_dynamic_real_features=0
            num_static_categorical_features=0
            num_static_real_features=0
            time_features=time_features_from_frequency_str(freq)

            # define the model
            n_vars=data_pred[add_select_region].shape[1]
            config=TimeSeriesTransformerConfig(
                input_size=n_vars,
                prediction_length=tst_kwargs['prediction_length'],
                context_length=tst_kwargs['context_length'],
                lags_sequence=lags_seq,
                num_time_features=len(time_features)+1,#time_features_from_frequency_str(freq)=3 and add another time feature called AgeFeature
                num_static_categorical_features=num_static_categorical_features,
                cardinality=[len(data_pred[add_select_region])],
                embedding_dimension=[3],

                encoder_layers=tst_kwargs['n_encoder_layers'],
                decoder_layers=tst_kwargs['n_decoder_layers'],
                d_model=tst_kwargs['d_model'],
            )
            model=TimeSeriesTransformerForPrediction(config)

            # train and forcast
            tst=TST_predict(data_pred[add_select_region],tst_kwargs['context_length'],tst_kwargs['prediction_length'])
            tst.gen_src_tgt(freq,config,tst_kwargs['train_dataloader_batch_size'],tst_kwargs['test_dataloader_batch_size'])
            forecast_array,loss_history=tst.predict(model,epochs=tst_kwargs['epochs'],logging_steps=tst_kwargs['logging_steps'])
            metric=tst.evaluate(forecast_array)

            # å¯è§†åŒ–å„ä¸ªåŒºåŸŸçš„é¢„æµ‹ç»“æœ
            tab_list=st.tabs(add_select_region)
            for idx,tab in enumerate(tab_list):
                with tab:
                    st.subheader(f'{add_select_region[idx]}çš„é¢„æµ‹ç»“æœ')
                    tst.plot(freq,idx,forecast_array)
            printMetric(model_name,metric)

        if model_name=='ğŸ¤— Informer':

            # hyperparameters
            lags_seq=[1,2,3]
            freq='1D'
            num_dynamic_real_features=0
            num_static_categorical_features=0
            num_static_real_features=0
            time_features=time_features_from_frequency_str(freq)

            # define the model
            n_vars=data_pred[add_select_region].shape[1]
            config=InformerConfig(
                input_size=n_vars,
                prediction_length=ifm_kwargs['prediction_length'],
                context_length=ifm_kwargs['context_length'],
                lags_sequence=lags_seq,
                num_time_features=len(time_features)+1,#time_features_from_frequency_str(freq)=3 and add another time feature called AgeFeature
                num_static_categorical_features=num_static_categorical_features,
                cardinality=[len(data_pred[add_select_region])],
                embedding_dimension=[3],

                encoder_layers=ifm_kwargs['n_encoder_layers'],
                decoder_layers=ifm_kwargs['n_decoder_layers'],
                d_model=ifm_kwargs['d_model'],
            )
            model=InformerForPrediction(config)

            # train and forcast
            ifm=Informer_predict(data_pred[add_select_region],ifm_kwargs['context_length'],ifm_kwargs['prediction_length'])
            ifm.gen_src_tgt(freq,config,ifm_kwargs['train_dataloader_batch_size'],ifm_kwargs['test_dataloader_batch_size'])
            forecast_array,loss_history=ifm.predict(model,epochs=ifm_kwargs['epochs'],logging_steps=ifm_kwargs['logging_steps'])
            metric=ifm.evaluate(forecast_array)
            
            # å¯è§†åŒ–å„ä¸ªåŒºåŸŸçš„ç»“æœ
            tab_list=st.tabs(add_select_region)
            for idx,tab in enumerate(tab_list):
                with tab:
                    st.subheader(f'{add_select_region[idx]}çš„é¢„æµ‹ç»“æœ')
                    ifm.plot(freq,idx,forecast_array)
            printMetric(model_name,metric)